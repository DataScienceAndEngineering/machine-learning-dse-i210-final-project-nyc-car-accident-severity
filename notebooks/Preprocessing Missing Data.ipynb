{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bd7018f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in d:\\anaconda\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in d:\\anaconda\\lib\\site-packages (from geopy) (2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d24764-c1e0-43c4-ac80-0b17c8c9b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6dc8a37-bebe-449f-af69-d761ff85d560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the folder\n",
    "folder_path = Path(\"C:/Users/crazy/OneDrive - The City College of New York/DSE I2100 - Applied Machine Learning and Data Mining/Project\")\n",
    "csv_file = folder_path.glob(\"*.csv\").__next__()\n",
    "\n",
    "# Load CSV file into DataFrame\n",
    "df = pd.read_csv(csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6245c75c-4c93-4a91-9860-1f356e8bfd31",
   "metadata": {},
   "source": [
    "## The Following code replaces 0 value rows with NaN for 'LATITUDE' & 'LONGITUDE' columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1570579b-367a-427a-8d80-04babb8fedb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         LATITUDE  LONGITUDE\n",
      "44            0.0        0.0\n",
      "47            0.0        0.0\n",
      "212           0.0        0.0\n",
      "252           0.0        0.0\n",
      "537           0.0        0.0\n",
      "...           ...        ...\n",
      "2066947       0.0        0.0\n",
      "2067378       0.0        0.0\n",
      "2069047       0.0        0.0\n",
      "2069552       0.0        0.0\n",
      "2070021       0.0        0.0\n",
      "\n",
      "[4350 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# verify we have valid coordinates in the data\n",
    "\n",
    "# Filter the DataFrame for latitude and longitude values less than 1 and greater than -1\n",
    "filtered_df = df[(df['LATITUDE'] < 1) & (df['LATITUDE'] > -1) | (df['LONGITUDE'] < 1) & (df['LONGITUDE'] > -1)]\n",
    "print(filtered_df[['LATITUDE','LONGITUDE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "963c6f08-a312-48ef-bfbf-1e463a928a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate coordinates for New York City:\n",
    "# Maximum Latitude: 40.9176 (Northernmost point of the Bronx)\n",
    "# Minimum Latitude: 40.4774 (Southernmost point of Staten Island)\n",
    "# Maximum Longitude: -73.7004 (Easternmost point of Queens)\n",
    "# Minimum Longitude: -74.2591 (Westernmost point of Staten Island)\n",
    "\n",
    "# Define the maximum and minimum values for latitude and longitude\n",
    "max_latitude = 40.9176\n",
    "min_latitude = 40.4774\n",
    "max_longitude = -73.7004\n",
    "min_longitude = -74.2591\n",
    "\n",
    "# Filter the DataFrame based on the conditions for latitude and longitude\n",
    "invalid_latitudes = (df['LATITUDE'] > max_latitude) | (df['LATITUDE'] < min_latitude)\n",
    "invalid_longitudes = (df['LONGITUDE'] > max_longitude) | (df['LONGITUDE'] < min_longitude)\n",
    "\n",
    "# Replace the values with NaN where the conditions are not met\n",
    "df.loc[invalid_latitudes, 'LATITUDE'] = np.nan\n",
    "df.loc[invalid_longitudes, 'LONGITUDE'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6375872c-f002-4bb6-a089-7834e52f13f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [LATITUDE, LONGITUDE]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "test_filtered_df = df[(df['LATITUDE'] < 1) & (df['LATITUDE'] > -1) | (df['LONGITUDE'] < 1) & (df['LONGITUDE'] > -1)]\n",
    "print(test_filtered_df[['LATITUDE','LONGITUDE']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623ef903-dd90-40b4-8293-6ea0eded2afa",
   "metadata": {},
   "source": [
    "## The following code creates a function to replace NaN values in the 'BOROUGH', 'ZIP CODE', 'ON STREET NAME' with actual values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c793989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find values for BOROUGH, ZIP CODE & ON STREET NAME using coordinates\n",
    "geolocator = Nominatim(user_agent=\"accident_severity_prediction\")\n",
    "\n",
    "def reverse_geocode(lat, lon, borough, zipcode, street_name):\n",
    "    \n",
    "    if np.isnan(lat) or np.isnan(lon) or bool(borough) == bool(zipcode) == bool(street_name) == \"True\":\n",
    "        #return [None, None, None]\n",
    "        return [np.nan, np.nan, np.nan]\n",
    "                                                                                                 \n",
    "    else:\n",
    "        \n",
    "        try:\n",
    "            location = geolocator.reverse((lat, lon))\n",
    "            address = location.raw\n",
    "            borough = address.get('address', {}).get('suburb')\n",
    "            zipcode = address.get('address', {}).get('postcode')\n",
    "            on_street_name = address.get('address', {}).get('road')\n",
    "            return [borough, zipcode, on_street_name]\n",
    "\n",
    "        except:\n",
    "            #return [None, None, None]\n",
    "            return [np.nan, np.nan, np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6cf365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the reverse_geocode function to each row of the dataframe\n",
    "new_values = df.apply(lambda row: reverse_geocode(row['LATITUDE'], row['LONGITUDE'], row['BOROUGH'], row['ZIP CODE'], row['ON STREET NAME']), axis=1, result_type='expand')\n",
    "\n",
    "# Replace NaN values in 'borough', 'zipcode', and 'address' columns with the corresponding values from the reverse_geocode function\n",
    "df['BOROUGH'].fillna(new_values[0], inplace=True)\n",
    "df['ZIP CODE'].fillna(new_values[1], inplace=True)\n",
    "df['ON STREET NAME'].fillna(new_values[2], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1936cd9d-8859-497a-adc8-34bcca7a550f",
   "metadata": {},
   "source": [
    "The function does not remove any existing values, only adds values to the 'BOROUGH', 'ZIP CODE', 'ON STREET NAME' columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e025457-5beb-47bc-95d6-bab9faa38bf0",
   "metadata": {},
   "source": [
    "Issue with trying to run big dataset with function, maybe add code to prevent iteration when borough, zipcode and onstreetname are not NaN\n",
    "\n",
    "1. Also, need to complete and make sure new values match dataset, like borough data\n",
    "2. convert zipcode data to float64\n",
    "3. convert borough and street name to str object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ed8f8d-78dc-4ef6-b675-d491cbbc1e3e",
   "metadata": {},
   "source": [
    "## Renaming duplicate values for \"BOROUGH\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fbe3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts of unique values in the \"BOROUGH\" column\n",
    "borough_counts = df['BOROUGH'].value_counts()\n",
    "\n",
    "# Print unique values and their counts\n",
    "print(\"Unique values and their counts in the 'BOROUGH' column:\")\n",
    "print(borough_counts)\n",
    "\n",
    "# Calculate the total sum of the counts\n",
    "total_sum = borough_counts.sum()\n",
    "print(\"Total sum of counts:\", total_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a37ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values in the \"BOROUGH\" column to lowercase\n",
    "df['BOROUGH'] = df['BOROUGH'].str.lower()\n",
    "\n",
    "# Replace specific values in the \"BOROUGH\" column\n",
    "df['BOROUGH'].replace({'the bronx': 'bronx', 'queens county': 'queens'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed2a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts of unique values in the \"BOROUGH\" column\n",
    "borough_counts = df['BOROUGH'].value_counts()\n",
    "\n",
    "# Print unique values and their counts\n",
    "print(\"Unique values and their counts in the 'BOROUGH' column:\")\n",
    "print(borough_counts)\n",
    "\n",
    "# Calculate the total sum of the counts\n",
    "total_sum = borough_counts.sum()\n",
    "print(\"Total sum of counts:\", total_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78b05b1-33a4-466e-8e3c-6ddc46df01cb",
   "metadata": {},
   "source": [
    "## Converting zipcodes to string objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23122466-119f-401b-9e4a-91076bd9ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts of unique values in the \"BOROUGH\" column\n",
    "zipcode_counts = df['ZIP CODE'].value_counts()\n",
    "\n",
    "# Print unique values and their counts\n",
    "print(\"Unique values and their counts in the 'ZIP CODE' column:\")\n",
    "print(zipcode_counts)\n",
    "\n",
    "# Calculate the total sum of the counts\n",
    "total_sum = zipcode_counts.sum()\n",
    "print(\"Total sum of counts:\", total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbffb38-6aa5-4dfd-b4a3-810cfee4146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'ZIP CODE' column to float, handling NaN values\n",
    "df['ZIP CODE'] = pd.to_numeric(df['ZIP CODE'], errors='coerce')\n",
    "\n",
    "# Convert 'ZIP CODE' column to int (this will automatically drop any decimal points)\n",
    "df['ZIP CODE'] = df['ZIP CODE'].astype(float).astype('Int64')  # Convert to Int64 to handle NaN and preserve integer dtype\n",
    "\n",
    "# Convert 'ZIP CODE' column back to string\n",
    "df['ZIP CODE'] = df['ZIP CODE'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66675f4d-9404-4175-8999-6f003e5ae598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts of unique values in the \"BOROUGH\" column\n",
    "zipcode_counts = df['ZIP CODE'].value_counts()\n",
    "\n",
    "# Print unique values and their counts\n",
    "print(\"Unique values and their counts in the 'ZIP CODE' column:\")\n",
    "print(zipcode_counts)\n",
    "\n",
    "# Calculate the total sum of the counts\n",
    "total_sum = zipcode_counts.sum()\n",
    "print(\"Total sum of counts:\", total_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97581895-341a-491d-88b6-fb8806b508d4",
   "metadata": {},
   "source": [
    "## Converting street names to lowercase string objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed36c49-2a88-49b2-9d27-f705747d7c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts of unique values in the \"BOROUGH\" column\n",
    "street_counts = df['ON STREET NAME'].value_counts()\n",
    "\n",
    "# Print unique values and their counts\n",
    "print(\"Unique values and their counts in the 'ZIP CODE' column:\")\n",
    "print(street_counts)\n",
    "\n",
    "# Calculate the total sum of the counts\n",
    "total_sum = street_counts.sum()\n",
    "print(\"Total sum of counts:\", total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86dec09-9a92-4879-80a2-3d41add39b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values in the \"BOROUGH\" column to lowercase\n",
    "df['ON STREET NAME'] = df['ON STREET NAME'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b38118-2316-42cc-b3ac-2dadd1e82677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts of unique values in the \"BOROUGH\" column\n",
    "street_counts = df['ON STREET NAME'].value_counts()\n",
    "\n",
    "# Print unique values and their counts\n",
    "print(\"Unique values and their counts in the 'ZIP CODE' column:\")\n",
    "print(street_counts)\n",
    "\n",
    "# Calculate the total sum of the counts\n",
    "total_sum = street_counts.sum()\n",
    "print(\"Total sum of counts:\", total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d7d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('Preprocessed_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68bb7b8-434e-43de-a187-6c187e712896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
